#! /usr/bin/env bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=25G
#SBATCH --export=ALL
#SBATCH --output=exp/logs/slurm-%J.log
#SBATCH --gres=gpu:1
#SBATCH --time=1:00:00

source scripts/preamble.slrm

# first determine if we've got cnn-mellin installed
if ! which cnn-mellin > /dev/null ; then
  echo -e "$0: cnn-mellin unavailable. Did you run 'pip install -e .'?"
  exit 1
fi

args=( "$@" )

# set model flag if we have it
if ! [[ "${args[*]}" =~ --model-dir ]]; then
  model_flag="--model-dir=${temp_dir}/models"
  echo "Could not find --model-dir flag. Adding '${model_flag}'"
  args+=( "$model_flag" )
fi

# set device flag if we have it
if ! [[ "${args[*]}" =~ --device ]]; then
  device_flag="--device=$( python -c 'import torch; print("cuda" if torch.cuda.is_available() else "cpu")')"
  echo "Could not find --device flag. Adding '$device_flag'"
  args=( "$device_flag" "${args[@]}" )
fi
if [[ "${args[*]}" =~ --device=cuda ]]; then
  nvidia-smi
fi

# this loop is primarily for optim when an estimate caused an OOM exception.
for x in $(seq 1 100); do
  cnn-mellin "${args[@]}"
  echo -e "Call ended with error (attempt $x/100)"
done

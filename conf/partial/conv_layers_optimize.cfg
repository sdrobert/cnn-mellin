[model]
mellin = false
nonlinearity = relu
dropout2d_on_conv = False

[training]
reduce_lr_burnin = 3
log10_learning_rate = -3.0179595342336354
reduce_lr_patience = 4
early_stopping_patience = 9
early_stopping_threshold = 0.22559355709795442
num_epochs = 26
reduce_lr_cooldown = 5
weight_decay = 7.630554894901822e-05
reduce_lr_factor = 0.40217742433715375
weigh_training_samples = True
reduce_lr_log10_epsilon = -8.552780681030011
early_stopping_burnin = 9
reduce_lr_threshold = 0.09667338695344271
optimizer = adam
dropout_prob = 0.2704656241667678

[train_data]
batch_size = 10

[optim]
initial_design_samples = 50
to_optimize = flatten_style, factor_sched, freq_factor, time_factor, kernel_sizes, hidden_sizes, context_left, context_right
partition_style = last
median_pruner_epoch_warmup = 5
sampler = tpe

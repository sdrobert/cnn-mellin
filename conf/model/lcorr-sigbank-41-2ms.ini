# == Help ==
# [model]
# convolutional_channel_factor: The factor by which to increase the size of the channel dimension after convolutional_factor_schedule layers
# convolutional_factor_schedule: The number of convolutional layers after the first layer before we modify the size of the time and frequency dimensions
# convolutional_freq_factor: The factor by which to reduce the size of the input along the frequency dimension after convolutional_factor_schedule layers
# convolutional_initial_channels: The number of channels in the initial convolutional layer
# convolutional_kernel_freq: The width of convolutional kernels along the frequency dimension
# convolutional_kernel_time: The width of convolutional kernels along the time dimension
# convolutional_layers: The number of layers in the convolutional part of the network
# convolutional_mellin: Whether the convolutional layers are mellin-linear (versus just linear)
# convolutional_nonlinearity: The pointwise convolutional_nonlinearity between convolutional layers. Choices: "relu", "sigmoid", "tanh"
# convolutional_time_factor: The factor by which to reduce the size of the input along the time dimension between convolutional layers
# recurrent_bidirectional: Whether the recurrent layers are bidirectional
# recurrent_layers: The number of recurrent layers in the recurrent part of the network
# recurrent_size: The size of each recurrent layer
# recurrent_type: The type of recurrent cell in the recurrent part of the network. Choices: "LSTM", "GRU", "RNN"
# seed: Seed used for weight initialization. If unset, does not change the torch stream
# use_lift: Whether to add the learnable lift operation to the network. Applied after log compression (if enabled)
# use_log_compression: Whether to add a pointwise log(1 + eps) layer to the input with learnable eps
# window_size: The total number of audio elements per window in time
# window_stride: The number of audio elements over to shift for subsequent windows

# [training]
# autocast: Whether to perform mixed-precision training. Only valid for CUDA
# convolutional_dropout_2d: If true, zero out channels instead of individual coefficients
# dropout_prob: The model dropout probability for all layers
# early_stopping_burnin: Number of epochs before the early stopping criterion kicks in
# early_stopping_patience: Number of epochs after which, if the classifier has failed to decrease its validation metric by a threshold, training is halted
# early_stopping_threshold: Minimum magnitude decrease in validation metric from the last best that resets the early stopping clock. If zero, early stopping will never be performed
# keep_last_and_best_only: If the model is being saved, keep only the model and optimizer parameters for the last and best epoch (in terms of validation loss). If False, save every epoch. See also "saved_model_fmt" and "saved_optimizer_fmt"
# log10_learning_rate: Initial optimizer log-learning rate. If unspecified, the initial learning rate of the optimizer instance remains unchanged
# max_freq_mask: SpecAgument max number of coefficients in frequency to mask per mask
# max_freq_warp: SpecAugment max frequency dimension warp during training
# max_shift_proportion: Randomly shift audio by up to this proportion of the sequence length on either side of the sequence (total possible proportion is twice this value)
# max_time_mask: SpecAugment absolute upper bound on sequential frames in time to mask per mask
# max_time_mask_proportion: SpecAugment relative upper bound on the number of sequential frames in time to mask per mask
# max_time_warp: SpecAugment max time dimension warp during training
# noise_eps: The proportion of gaussian noise per coefficient to add to the input
# num_epochs: Total number of epochs to run for. If unspecified, runs until the early stopping criterion (or infinitely if disabled) 
# num_freq_mask: SpecAugment maximum number of frequency masks to apply
# num_time_mask: SpecAgument absolute upper bound on the number of temporal masks to apply
# num_time_mask_proportion: SpecAugment relative upper bound on the number of temporal masks to apply
# optimizer: Which method of gradient descent to perform. Choices: "adam", "sgd", "rms"
# reduce_lr_burnin: Number of epochs before the criterion for reducing the learning rate kicks in
# reduce_lr_cooldown: Number of epochs after reducing the learning rate before we resume checking improvements
# reduce_lr_factor: Factor by which to multiply the learning rate if there has been no improvement in the  after "reduce_lr_patience" epochs
# reduce_lr_log10_epsilon: The log10 absolute difference between learning rates that, below which, reducing the learning rate is considered meaningless
# reduce_lr_patience: Number of epochs after which, if the classifier has failed to decrease its validation metric by a threshold, the learning rate is reduced
# reduce_lr_threshold: Minimum magnitude decrease in validation metric from the last best that resets the clock for reducing the learning rate. If zero, the learning rate will never be reduced
# saved_model_fmt: The file name format string used to save model state information. Entries from the state csv are used to format this string (see TrainingStateController)
# saved_optimizer_fmt: The file name format string used to save optimizer state information. Entries from the state csv are used to format this string (see TrainingStateController)
# seed: Seed used for training procedures (e.g. dropout). If unset, will not touch torch's seeding

# [data]
# batch_size: Number of elements in a batch, which equals the number of utterances in the batch
# drop_last: Whether to drop the last batch if it does reach batch_size
# eos: A special symbol used to indicate the end of a sequence in reference and hypothesis transcriptions. If set, `eos` will be appended to every reference transcription on read
# sos: A special symbol used to indicate the start of a sequence in reference and hypothesis transcriptions. If set, `sos` will be prepended to every reference transcription on read
# subset_ids: A list of utterance ids. If non-empty, the data set will be restricted to these utterances. A JSON object


[model]
convolutional_channel_factor = 1
convolutional_factor_schedule = 1
convolutional_freq_factor = 1
convolutional_initial_channels = 57
convolutional_kernel_freq = 15
convolutional_kernel_time = 7
convolutional_layers = 3
convolutional_mellin = False
convolutional_nonlinearity = relu
convolutional_time_factor = 2
recurrent_bidirectional = True
recurrent_layers = 5
recurrent_size = 967
recurrent_type = GRU
seed
use_lift = False
use_log_compression = True
window_size = 9
window_stride = 3

[training]
autocast = False
convolutional_dropout_2d = False
dropout_prob = 0.0
early_stopping_burnin = 0
early_stopping_patience = 1
early_stopping_threshold = 0.0
keep_last_and_best_only = True
log10_learning_rate
max_freq_mask = 10000
max_freq_warp = 0.0
max_shift_proportion = 0.0
max_time_mask = 10000
max_time_mask_proportion = 0.04
max_time_warp = 0.0
noise_eps = 0.0
num_epochs = 100
num_freq_mask = 0
num_time_mask = 0
num_time_mask_proportion = 0.04
optimizer = adam
reduce_lr_burnin = 0
reduce_lr_cooldown = 0
reduce_lr_factor = 0.1
reduce_lr_log10_epsilon = -8.0
reduce_lr_patience = 1
reduce_lr_threshold = 0.0
saved_model_fmt = model_{epoch:03d}.pt
saved_optimizer_fmt = optim_{epoch:03d}.pt
seed

[data]
batch_size = 16
drop_last = False
eos
sos
subset_ids = []

